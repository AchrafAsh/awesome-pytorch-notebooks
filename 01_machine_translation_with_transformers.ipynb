{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_machine_translation_with_transformers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPdSDfPBcaX9ZuPeUyaDMLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/awesome-pytorch-notebooks/blob/main/01_machine_translation_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO924A6qHPU2"
      },
      "source": [
        "# Machine Translation with Transformers\n",
        "\n",
        "<img src=\"https://pytorch.org/tutorials/_images/transformer_architecture.jpg\" width=\"400px\" />\n",
        "\n",
        "Official Pytorch Tutorial: https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcFwTVArGaA7"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence  # padding of every batch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "from typing import List"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NiuHggKCXH0"
      },
      "source": [
        "## The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDiVLmONfp3"
      },
      "source": [
        "### Dataset and Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dpk5gjlCWxB",
        "outputId": "ce618289-f874-43ab-f93c-4b85f9854ba0"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download fr"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: fr_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz#egg=fr_core_news_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpGb9yr4KyRS"
      },
      "source": [
        "fr_tokenizer = get_tokenizer('spacy', language='fr')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjWx3za7Kobo"
      },
      "source": [
        "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
        "train_urls = ('train.fr.gz', 'train.en.gz')\n",
        "val_urls = ('val.fr.gz', 'val.en.gz')\n",
        "test_urls = ('test_2016_flickr.fr.gz', 'test_2016_flickr.en.gz')\n",
        "\n",
        "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeUsuXLwD_SO"
      },
      "source": [
        "def build_vocab(filepath, tokenizer):\n",
        "    counter = Counter()\n",
        "    with io.open(filepath, encoding=\"utf8\") as f:\n",
        "        for string_ in f:\n",
        "            counter.update(tokenizer(string_))\n",
        "    return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_enQSO1xKkrc"
      },
      "source": [
        "fr_vocab = build_vocab(train_filepaths[0], fr_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X3Ql86SKlB5"
      },
      "source": [
        "def data_process(filepaths):\n",
        "    raw_fr_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "    raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "    data = []\n",
        "    for (raw_fr, raw_en) in zip(raw_fr_iter, raw_en_iter):\n",
        "        fr_tensor_ = torch.tensor([fr_vocab[token] for token in fr_tokenizer(raw_fr)],\n",
        "                                dtype=torch.long)\n",
        "        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
        "                                dtype=torch.long)\n",
        "        data.append((fr_tensor_, en_tensor_))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHYf_Z80GI4Y"
      },
      "source": [
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "test_data = data_process(test_filepaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhAJYMOILKWw"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZg63WQ-LNPC"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "PAD_IDX = de_vocab['<pad>']\n",
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UImtRWgLWVG"
      },
      "source": [
        "def generate_batch(data_batch):\n",
        "    fr_batch, en_batch = [], []\n",
        "    for (fr_item, en_item) in data_batch:\n",
        "        fr_batch.append(torch.cat([torch.tensor([BOS_IDX]), fr_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n",
        "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "    return fr_batch, en_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EycDFgOCLXjj"
      },
      "source": [
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "                       shuffle=True, collate_fn=generate_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT59YamRGgn5"
      },
      "source": [
        "## The model\n",
        "\n",
        "- Embeddings → encode one-hot-encoded words as continuous vectors to catch semantic (might use pre-trained word2vec for that)\n",
        "- Transformer Block stacked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TL1qyXLG91p"
      },
      "source": [
        "class Translator(nn.Module):\n",
        "    def __init__(self, \n",
        "                 src_vocab_size: int,\n",
        "                 trgt_vocab_size: int,\n",
        "                 hidden_dim:int=124,\n",
        "                 word_vectors=None):\n",
        "        \n",
        "        super().__init__()\n",
        "        if word_vectors not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(weight)\n",
        "            assert hidden_dim == weight.size(0) # TODO: update to make sure the output is the same as the input of the transformer\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(num_embeddings=src_vocab_size,\n",
        "                                          embedding_dim=hidden_dim)\n",
        "        \n",
        "        self.transformer = nn.Transformer(d_model=hidden_dim, nhead=8) # docs: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "    \n",
        "    def load_embeddings(self, keyed_vectors):\n",
        "        self.embedd\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src, tgt = self.embedding(src), self.embedding(tgt)\n",
        "        return self.transformer(src, tgt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buDQqPcu6uC3"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nys1GAm9Nnij"
      },
      "source": [
        "### Optional: pre-trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jU7k7904V8u"
      },
      "source": [
        "# TODO: download a pre-trained word2vec (a very small one to see if a pre-trained yield better results)\n",
        "!wget "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8aTBPcKHU1H"
      },
      "source": [
        "# Load pre-trained word vectors\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('path/to/file')\n",
        "weights = torch.FloatTensor(model.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-keqRKKNxuy"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P6rdFgG4er8"
      },
      "source": [
        "def run(model:nn.Module,\n",
        "        iterator: DataLoader,\n",
        "        epochs: int,\n",
        "        lr:float=0.01,\n",
        "        weight_decay:float=0.001):\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        total_loss = 0\n",
        "        for idx, data in enumerate(dataset):\n",
        "            src, tgt = zip(data)\n",
        "            loss = train(model, src, tgt, optimizer)\n",
        "            total_loss += loss\n",
        "\n",
        "        print(f\"Epoch: [{epoch} / {epochs}] | Loss: {total_loss}\")\n",
        "\n",
        "\n",
        "def train(model, src, tgt, optimizer):\n",
        "    PAD_IDX = en_vocab.stoi['<pad>']\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "    model.train()\n",
        "    output = model(src, tgt)\n",
        "    loss = nn.CrossEntropyLoss()(output, tgt[])\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "    \n",
        "\n",
        "def evaluate(model, dataset):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    for idx, data in enumerate(dataset):\n",
        "        src, tgt = zip(data)\n",
        "        output = model(src, tgt)\n",
        "        loss = criterion(output, tgt)\n",
        "        total_loss += loss\n",
        "    \n",
        "    print(f\"Total Loss: {total_loss}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyFOur09Ntt0"
      },
      "source": [
        "INPUT_DIM = len(de_vocab)\n",
        "OUTPUT_DIM = len(en_vocab)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQvriU1pN9Na"
      },
      "source": [
        "model = Translator()\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"The model has {count_parameters(model):,} parameters 🚀\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyts29FaORmT"
      },
      "source": [
        "run(model, train_iter, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY_b6zYC6Rqy"
      },
      "source": [
        "# Building the Transformer from scratch\n",
        "\n",
        "- Attention is all you need: [link to paper]\n",
        "\n",
        "[image of the architecture]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guANqzKl6Ysf"
      },
      "source": [
        "## Self-Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwapU3Ax6j_m"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "\tdef __init__(self, k, heads=8):\n",
        "\t\tsuper(SelfAttention, self).__init__()\n",
        "\t\tself.k, self.heads = k, heads\n",
        "\n",
        "\t\t# these compute the queries, keys, values for all\n",
        "\t\t# heads (as a single concatenated vector)\n",
        "\t\tself.tokeys = nn.Linear(k, k * heads, bias=False)\n",
        "\t\tself.toqueries = nn.Linear(k, k * heads, bias=False)\n",
        "\t\tself.tovalues = nn.Linear(k, k * heads, bias=False)\n",
        "\n",
        "\t\t# this unifies the outputs of the different heads into a single k-vector\n",
        "\t\tself.unifyheads = nn.Linear(heads * k, k)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tb, t, k = x.size()\n",
        "\t\th = self.heads\n",
        "\n",
        "\t\tqueries = self.toqueries(x).view(b, t, h, k)\n",
        "\t\tkeys = self.tokeys(x).view(b, t, h, k)\n",
        "\t\tvalues = self.values(x).view(b, t, h, k)\n",
        "\t\t# - fold heads into the batch dimension\n",
        "\t\tkeys = keys.transpose(1, 2).contiguous().view(b * h, t, k)\n",
        "\t\tqueries = queries.transpose(1, 2).contiguous().view(b * h, t, k)\n",
        "\t\tvalues = values.transpose(1, 2).contiguous().view(b * h, t, k)\n",
        "\n",
        "\t\tqueries = queries / (k ** (1/4))\n",
        "\t\tkeys = keys / (k ** (1/4))\n",
        "\n",
        "\t\t# - get dot product of queries and keys, and scale\n",
        "\t\tdot = torch.bmm(queries, keys.transpose(1, 2))\n",
        "\t\t# - dot has size (b*h, t, t) containing raw weights\n",
        "\n",
        "\t\tdot = F.softmax(dot, dim=2)\n",
        "\t\t# - dot now contains row-wise normalized weights\n",
        "\n",
        "\t\t# apply the self attention to the values\n",
        "\t\tout = torch.bmm(dot, values).view(b, h, t, k)\n",
        "\n",
        "\t\t# - swap h, t back  and unify heads\n",
        "\t\tout = out.transpose(1, 2).contiguous().view(b, t, h * k)\n",
        "\t\treturn self.unifyheads(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1KokvOF6b17"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljb6h5dJ6kbi"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\tdef __init__(self, k, heads):\n",
        "\t\tsuper().__init__()\n",
        "\n",
        "\t\tself.attention = SelfAttention(k, heads=heads)\n",
        "\n",
        "\t\tself.norm1 = nn.LayerNorm(k)\n",
        "\t\tself.norm2 = nn.LayerNorm(k)\n",
        "\n",
        "\t\tself.ff = nn.Sequential(\n",
        "\t\t\tnn.Linear(k, 4*k),\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Linear(4*k, k)\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tattended = self.attention(x)\n",
        "\t\tx = self.norm1(attended + x)\n",
        "\n",
        "\t\tfedforward = self.ff(x)\n",
        "\t\treturn self.norm2(fedforward + x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhSrN81V6d0I"
      },
      "source": [
        "## Encoder / Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-9H52uw6lLx"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx4JMC4yYmwQ"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_IpMK7c6ggH"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzK3_5ng6lpZ"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "\tdef __init__(self, k, heads, depth, seq_length, num_tokens, num_classes):\n",
        "\t\tsuper().__init__()\n",
        "\n",
        "\t\tself.num_tokens = num_tokens\n",
        "\t\tself.token_emb = nn.Embedding(num_tokens, k)\n",
        "\t\tself.pos_emb = nn.Embedding(seq_length, k)\n",
        "\n",
        "\t\t# the sequence of transformer blocks that does all the heavy lifting\n",
        "\t\ttblocks = []\n",
        "\t\tfor i in range(depth):\n",
        "\t\t\ttblocks.append(TransformerBlock(k=k, heads=heads))\n",
        "\t\tself.tblocks = nn.Sequential(*tblocks)\n",
        "\n",
        "\t\t# maps the final output sequence to class logits\n",
        "\t\tself.toprobs = nn.Linear(k, num_classes)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t\"\"\"\n",
        "\t\t:param x: A (b,t) tensor of integer values representing words \n",
        "\t\t\t\t(in some predetermined vocabulary)\n",
        "\t\t:return: A (b, c) tensor of log-probabilities over the classes\n",
        "\t\t\t\t(where c is the nr. of classes)\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# generate token embeddings\n",
        "\t\ttokens = self.token_emb()\n",
        "\t\tb, t, k = tokens.size()\n",
        "\n",
        "\t\t# generate position embeddings\n",
        "\t\tpositions = torch.arange(t)\n",
        "\t\tpositions = self.pos_emb(positions)[None, :, :].expand(b, t, k)\n",
        "\n",
        "\t\tx = tokens + positions\n",
        "\t\tx = self.tblocks(x)\n",
        "\n",
        "\t\t# average-pool over the t dimension and project to class probabilities\n",
        "\t\tx = self.toprobs(x.mean(dim=1))\n",
        "\t\treturn F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}